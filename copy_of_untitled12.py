# -*- coding: utf-8 -*-
"""Copy of Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oLMw2qay9Ab0Jw4KczaCzplReW_KqNUJ
"""

!pip install PyICU

import seaborn as sns

import icu
import re
import nltk
import math
import codecs
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
from collections import Counter
import matplotlib.pyplot as plt



# nltk.download('all')
nltk.download('punkt')

"""###main code area###
 open file using codecs(this will handle errors during encoding process) and proceed
"""

with codecs.open('/content/our_dataset2.txt','r',encoding = 'utf-8',errors= 'ignore') as myfile:
  text = myfile.read()
text

"""##tokenization##

  
*  removing the markup and other non amharic words using regular expression

  *  using built in function tokenize the text 





"""

text = re.sub(r'[^\u1200-\u137F\s\w]+', '', text)
english_words_pattern = r'\b[a-zA-Z]+\b'
text = re.sub(english_words_pattern, '', text)

text = re.sub(r'[^\u1200-\u137F\s]+', '', text)
amharic_punctuation = "።፣፡፤፥፨፦፧፨፠"
translator = str.maketrans('', '', amharic_punctuation)
text = text.translate(translator).lower()
print(text)

words = word_tokenize(text)

words

"""##find the word_frequency##"""

word_freq = Counter(words)
word_freq

"""get the number of total words in our document"""

total_words = len(words)
total_words

"""##**calculate the ##entropy## of the word**##"""

word_entropy = {}
i = 0
for word , freq in word_freq.items():
  prob = freq / total_words
  i += 1
  entropy = - (prob) * math.log(prob,2)
  word_entropy[word] = entropy
word_entropy

"""##calculate the index##"""

import heapq

dict_for_index = {word :word_freq[word] * word_entropy[word]  for word in word_freq.keys()}

# least_300_words = heapq.nsmallest(300, dict_for_index, key=dict_for_index.get)

# least_300_words
# import heapq

top_300_words = heapq.nlargest(300, dict_for_index, key=dict_for_index.get)
top_300_words

words_Without_stop_words = [word for word in words if not word in top_300_words]
len(words_Without_stop_words)

"""**set the thershold and remove the stop words**

to make sure about the stop_words ,use 115 lists of well known stop words
"""

well_known_stop_words =  [
    "እኔ", "የእኔ", "እኔ ራሴ", "እኛ", "የእኛ", "የእኛ", "እኛ ራሳችን", "አንቺ", "ያንተ", "ራስህን",
    "እራሳችሁ", "እሱ", "የእሱ", "ራሱ", "እሷ", "የእሷ", "እራሷ", "እነሱ", "እነሱን", "የእነሱ",
    "ራሳቸው", "ምንድን", "የትኛው", "የአለም", "ጤና", "ድርጅት", "ማን", "ይህ", "የሚል",
    "ነው", "ናቸው", "ነበር", "ነበሩ", "ሁን", "ቆይቷል", "መሆን", "አላቸው", "አለው", "ነበረው",
    "ያለው", "መ", "ስ", "ራ", "ት", "ያደርጋል", "አደረገ", "ማድረግ", "አንድ", "የ", "እና",
    "ግን", "ከሆነ", "ወይም", "ምክንያቱም", "እንደ", "እስከ", "እያለ", "ለ", "ጋር", "ስለ", "ላይ",
    "መካከል", "ወደ", "በኩል", "ወቅት", "ከዚህ", "በፊት", "በኋላ", "ከላይ", "ከታች", "ወደከ",
    "ወደ", "ላይ", "ታች", "ውስጥ", "ውጭ", "ላይ", "ጠፍቷል", "በላይ", "በታች", "እንደገና",
    "ተጨማሪ", "ከዚያ", "አንድ", "ጊዜ", "እዚህ", "እዚያ", "መቼ", "የት", "እንዴት", "ሁሉም",
    "ማንኛውም", "ሁለቱም", "እያንዳንዳቸው", "ጥቂቶች", "ተጨማሪ", "በጣም", "ሌላ", "አንዳንድ",
    "እንደዚህ", "አይ", "ወይም", "አይደለም", "አይደለም", "ብቻ", "የራሱ", "ተመሳሳይ", "ስለዚህ",
    "ይልቅ", "እንዲሁ", "በጣም", "ት", "ይችላል", "ያደርጋል", "ብቻ", "ዶን", "ይገባል", "አሁን","ውስጥ","እና"
]

updated_words = [word for word in words_Without_stop_words if not word in well_known_stop_words]
len(updated_words)

"""##**stemming**##"""

def stem_prefix_suffix(word):
    prefixes = ["የ", "ለ", "አል", "በ", "ሳይ", "አት", "አስ", "እንደ", "እስኪ", "ያል", "ባለ", "እንዲ", "እያስ", "በስተ", "ወደ", "ያስ", "ት", "ስለ", "እስክ", "ሲ", "እንድ","አስ", "ምት", "በስተ", "ወደ", "ያለ", "ማይ", "የ", "ሳት","ያስ", "እንዲ", " ት", "ያ", "አላ", "እስከ", "በ", "ተ", "ት", "ሚ", "እን", "በት", "ከ", "ተ", "ወ", "አይ", "የ"]
    suffixes = ["ን", "ና", "ሽ", "ነት","ሽው", "ው","ዮሽ", "ቸው", "ህ", "ባት", "ዋ", "ችኋል", "ዎች", "ም", "ለን", "ለት", "ዊ","ቹ", "ውያን", "ዎች", "ዋ", "ኝ", "ኞች", "ያ", "ችን", "ቸው","ች", "ቸው" "ዊ", "በት", "ችሁ", "ዋ", "ን", "ህ","ኛ", "አቸዋል","አችን","ቹ", "ችሁ", "ውያን", "ቻቸው", " ይ", "ቸው", "ህ", "ኞቸ", "ለ", "ት"]

    word=word.replace("ሠ","ሰ")
    word=word.replace("ሃ", "ሀ")
    word=word.replace("ሐ", "ሀ")
    word=word.replace("ሓ", "ሀ")
    word=word.replace("ኅ", "ሀ")
    word=word.replace("ኃ", "ሀ")
    word=word.replace("ኋ", "ኋ")
    word=word.replace("ሗ", "ኋ")
    word=word.replace("ኁ", "ሁ")
    word=word.replace("ኅ", "ህ")
    word=word.replace("ኂ", "ሂ")
    word=word.replace("ኄ", "ሄ")
    word=word.replace("ሑ", "ሁ")
    word=word.replace("ሒ", "ሂ")
    word=word.replace("ሔ", "ሄ")
    word=word.replace("ሕ", "ህ")
    word=word.replace("ሡ", "ሱ")
    word=word.replace("ሖ", "ሆ")
    word=word.replace("ሢ", "ሲ")
    word=word.replace("ሣ", "ሳ")
    word=word.replace("ሤ", "ሴ")
    word=word.replace("ሥ", "ስ")
    word=word.replace("ሦ", "ሶ")
    word=word.replace("ጸ", "ፀ")
    word=word.replace("ጹ", "ፁ")                    
    word=word.replace("ጺ", "ፂ")
    word=word.replace("ጻ", "ፃ")
    word=word.replace("ጼ", "ፄ")
    word=word.replace("ጽ", "ፅ")
    word=word.replace("ጾ", "ፆ")
    word=word.replace("ዉ", "ው")
    word=word.replace("ዪ", "ይ")
    word=word.replace("ዓ", "አ")
    word=word.replace("ዑ", "ኡ")
    word=word.replace("ዒ", "ኢ")
    word=word.replace("ዐ", "አ")
    word=word.replace("ኣ", "አ")
    word=word.replace("ዔ", "ኤ")
    word=word.replace("ዕ", "እ")
    word=word.replace("ዖ", "ኦ")

    if word.startswith('አ') and word.endswith('ጥ'):
        word = word[:-1] 
        if word.startswith('አ'):
             word = word[1:]
             return word
    if word.startswith('አ') and word.endswith('ል'):
        word = word[:-1] 
        if word.startswith('አ'):
             word = word[1:]
             return word
    if word.startswith('አ') and word.endswith('ብ'):
        word = word[:-1] 
        if word.startswith('አ'):
             word = word[1:] 
             return word
    if word.startswith('አስ') and word.endswith('ች'):
        word = word[:-1] 
        if word.startswith('አስ'):
             word = word[2:]
             return word
                     

    elif word.endswith('ጆች'):
        word = word[:-2] + 'ጅ'
        return word
    elif word.endswith('ቶች'):
        word = word[:-2] + 'ት'
        return word
    elif word.endswith('ኞች'):
        word = word[:-2] + 'ኛ'
        return word
    elif word.endswith('ጎች'):
        word = word[:-2] + 'ግ'
        return word

    for prefix in prefixes:
        if word.startswith(prefix):
            word = word[len(prefix):]  
            break

    for suffix in suffixes:
        if word.endswith(suffix):
            word = word[:-len(suffix)]
            break
    return word

updated_words = [stem_prefix_suffix(word) for word in updated_words if len(word) > 1]
updated_words = [ word for word in updated_words if len(word) > 1 ]
new_dict_to_count_freq = Counter(updated_words)
new_dict_to_count_freq

"""###**scop reduction**###

*  do some math inorder to know the feasible region to work with



"""

min_cut_point = 0.0003
max_cut_point  = 0.0134
words_filtered = [word for word in updated_words if min_cut_point <= new_dict_to_count_freq[word]/total_words <= max_cut_point  ]
words_filtered

"""get the frequency of words in filtered word list and put them in new list"""

freq_of_each_word_in_filtered = [new_dict_to_count_freq[word] for word in words_filtered]
freq_of_each_word_in_filtered

"""###**sort the words_filtered based on their frequency**###"""

words_filtered_sorted = [x for _,x in sorted(zip(freq_of_each_word_in_filtered,words_filtered))][::-1]
words_filtered_sorted

freq_in_words_filtered_sorted = Counter(words_filtered_sorted)
freq_in_words_filtered_sorted

"""### **calculate the rank of the word**###"""

new_dict = {}
temp  = 1
for word in freq_in_words_filtered_sorted.keys():
  new_dict[word] = temp
  temp += 1
new_dict

frequency = [new_dict_to_count_freq[word] for word in new_dict.keys() ]
frequency



"""##**visualization**##

**draw frequency versus rank graph for the most_common 10 words**
"""

rank = new_dict.values()
plt.plot(rank,frequency, linewidth=6, linestyle='-', marker='o', markersize=16, color='green', markerfacecolor='red', markeredgecolor='blue')
plt.xlabel('rank')
plt.ylabel('frequncy')
plt.grid = True
plt.title('rank vs freq graph' )
plt.show()

"""##**scatter plot**##

"""

# entropy = [word_entropy[word] for word in words_filtered]
rank = new_dict.values()
s = [new_dict[word] * 10 for word in new_dict]

plt.scatter(rank, frequency, s=s, c='blue', marker='o', alpha=0.2)
plt.xlabel('Rank')
plt.ylabel('Frequency')
plt.title('Word Frequency vs Rank')
plt.show()

"""### **there is a steep decline in frequency as the rank increases, it suggests that there are a few words that occur very frequently, while the majority of words occur less frequently**

#**assignment one**#
"""

import re
import codecs
import matplotlib.pyplot as plt

"""###read the file###"""

with codecs.open('/content/our_dataset2.txt','r',encoding = 'utf-8',errors= 'ignore') as myfile:
  text = myfile.read()
text

"""##remove markups##"""

text = re.sub(r'[^\u1200-\u137F\s\w]+', '', text)
english_words_pattern = r'\b[a-zA-Z]+\b'
text = re.sub(english_words_pattern, '', text)
text = re.sub(r'[^\u1200-\u137F\s]+', '', text)
amharic_punctuation = "።፣፡፤፥፨፦፧፨፠"
translator = str.maketrans('', '', amharic_punctuation)
text = text.translate(translator).lower()
print(text)

"""##statistical property##

frequency of each word
"""

words_freq_holder_dict = {}
for word in text.split():
  if word in words_freq_holder_dict:
    words_freq_holder_dict[word] += 1
  else:
    words_freq_holder_dict[word] = 1
words_freq_holder_dict

"""rank the words according to their frequency """

sorted_dict = sorted(words_freq_holder_dict.items(), key = lambda x : x[1] , reverse = True ) #store the tuple ( word , frequncy )
freq_holder = []
word_holder = []
for word,freq in  sorted_dict:
  freq_holder.append(freq)
  word_holder.append(word)
word_holder
freq_holder
sorted_dict

"""##pritn top 10 words##"""

for i in range(10):
  print(sorted_dict[i])

"""rank for each word """

rank_for_each_word = {}
for i ,word in enumerate(word_holder):
  rank = i + 1
  rank_for_each_word[word] = rank
  product = rank * freq_holder[i]
rank_for_each_word

"""###visualize the graph"""

plt.plot(rank_for_each_word.values(),freq_holder, linewidth=6, linestyle='-', marker='o', markersize=16, color='green', markerfacecolor='black', markeredgecolor='blue')
plt.xlabel('rank')
plt.ylabel('frequncy')
plt.grid = True
plt.title('rank vs freq graph' )
plt.show()

